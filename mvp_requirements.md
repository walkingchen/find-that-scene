项目名称：文本驱动的视频镜头检索系统（MVP）

目标：
用户输入一句自然语言文本（如：“他在黑暗中奔跑”），系统返回一部视频中最相关的镜头（起止时间段），并支持播放前 3~5 条结果。

---------------------------
一、核心功能模块
---------------------------
1. 视频预处理模块
   - 镜头切分（基于内容）
   - 提取每个镜头的中间帧图像

2. 特征向量生成模块
   - 使用 OpenAI CLIP 对图像帧生成语义向量

3. 向量索引模块
   - 使用 FAISS 建立镜头向量索引

4. 文本检索接口
   - 将用户文本转向量
   - 在索引中搜索语义最接近的镜头

5. 结果返回模块
   - 返回镜头编号、起止时间、对应片段视频
   - 可通过播放器播放该镜头片段

---------------------------
二、技术栈
---------------------------
- 编程语言：Python 3.10+
- 模型：OpenAI CLIP（ViT-B/32）
- 视频切分：PySceneDetect
- 视频处理：FFmpeg
- 向量检索：FAISS
- 后端接口：FastAPI
- UI 原型：Gradio
- 环境管理：Docker

---------------------------
三、系统流程
---------------------------
1. 视频 → 镜头切分 → 提取镜头中帧图像
2. 图像帧 → CLIP encode → scene_vectors.npy
3. scene_vectors.npy → FAISS index
4. 用户输入文本 → CLIP encode → 向量检索
5. 返回匹配镜头编号 → 视频剪辑 → 播放镜头片段

---------------------------
四、目录结构建议
---------------------------
project/
├── video/                # 输入视频
├── scenes/               # 镜头图像 & 视频片段
├── embeddings/           # 向量数据 & 索引
├── main.py               # FastAPI 后端接口
├── ui.py                 # Gradio UI
├── tools/                # 预处理脚本
├── requirements.txt
└── README.md

---------------------------
五、测试要求
---------------------------
- 支持输入一条文本
- 返回匹配镜头的起止时间及视频片段（scene_xx.mp4）
- 片段可播放，时长约 3～5 秒
- 检索速度 < 1 秒（镜头数量 < 1000）
- 可通过 `/search?query=xxx` 接口访问
- Web UI 支持文本框输入 + 镜头播放

---------------------------
六、依赖（requirements.txt）
---------------------------
scenedetect
ffmpeg-python
faiss-cpu
torch
ftfy
regex
tqdm
opencv-python
clip-by-openai
fastapi
uvicorn
gradio

---------------------------
七、开发阶段建议
---------------------------
Step 1: PySceneDetect 切镜头 + 截帧
Step 2: CLIP 编码图像帧 → 向量
Step 3: 构建 FAISS 索引
Step 4: FastAPI 查询接口开发
Step 5: Gradio 前端原型

---------------------------
八、MVP 限制说明
---------------------------
- 暂时仅支持一个视频
- 每个镜头仅提取一帧
- 不支持镜头平均特征
- UI 简洁（无账号、权限系统）
- 不提供字幕、反向问答功能

---------------------------
九、完成标准
---------------------------
- 完整支持镜头检索与播放
- 查询接口响应时间快
- 向量索引持久化存储
- 可部署运行于本地机器或 Docker 容器中
